## 为何Kafka这么"快"

**从高度抽象的角度来看，性能问题逃不出下面三个方面：**
- 网络 
- 磁盘 
- 复杂度

对于 Kafka 这种网络分布式队列来说，**网络和磁盘**更是优化的重中之重。针对于上面提出的抽象问题，解决方案高度抽象出来也很简单：
- 并发 
- 压缩 
- 批量 
- 缓存 
- 算法

以下设计使得Kafka很快 
1. 零拷贝网络和磁盘优秀的网络模型，基于 Java NIO 
> 零拷贝就是尽量去减少上面数据的拷贝次数，从而减少拷贝的 CPU 开销，减少用户态内核态的上下文切换次数，从而优化数据传输的性能。 
> Reactor 模型
2. 高效的文件数据结构设计
> 设计的部分：
> - Segment(index file、data file)
> - segment 文件命名规则
> - index 采用稀疏索引
> - 稀疏索引文件较小 -> mmap(内存映射)
> 具体查找流程：
> 1. 按照二分法找到小于 offset 的 segment 的.log 和.index
> 2. 用目标 offset 减去文件名中的 offset 得到消息在这个 segment 中的偏移量
> 3. 用二分法在 index 文件中找到对应的索引
> 4. 到 log 文件中，顺序查找，直到找到 offset 对应的消息。
3. Parition 并行和可扩展 
4. 数据批量传输 
5. 数据压缩 
6. 顺序读写磁盘 
> 采用追加写的方式，说白了Kafka就是一个Queue

顺序读写磁盘 为什么效率高?
- 首先，磁盘是通过旋转盘片和移动磁头读写数据的，因此，相邻的数据所在的扇区通常是连续的，而距离较远的数据则通常分散在磁盘的不同区域。这就意味着，顺序读写数据可以最大程度地利用磁头的移动速度和寻道时间，而随机读写数据则需要频繁地移动磁头，因此效率较低。
- 其次，操作系统的IO调度算法也会对磁盘的读写效率产生影响。大多数操作系统都采用了一些算法来优化磁盘IO操作的调度，以提高系统的整体性能。其中，常用的算法包括CFQ算法、Deadline算法和NOOP算法等。这些算法都优先考虑顺序IO请求，以便利用磁盘的顺序读写特性，从而提高系统的磁盘IO效率。
- 因此，顺序读写磁盘可以最大程度地利用磁盘的物理特性和操作系统的IO调度算法，从而获得更高的读写效率。
